\section{Learnig with L* }
\label{section:L}

The L* algorithm, described by Dana Angluin in \cite{LPaper}, is a learning algorithm. Its goal is to build a \textit{minimal} DFA recognizing an unknown language \langU{} thanks to interactions between a \learner{} and a \teacher{} through membership and equivalence queries.

\begin{definition}[Type of queries]
  A membership query is represented as a function which maps a word $w$ to \{True, False\} and an equivalence query maps an automaton \automaton{} to \{True, $w \in \Sigma^*$\}, where $w$ is a counter-exemple if \automaton{} does not recognize \langU{}.
\end{definition}

\begin{definition}[Counter-exemple]
  A counter-example is a word belonging to the symmetric difference of \langU{} and $L(\automatonN{})$. The symmetric difference between to sets $A$ and $B$ is a set $S$ containing all the elements that are in $A$ and not in $B$ or that are in $B$ and not in $A$, we can note it as : $A \Delta B \equiv (A \cap \bar{B}) \cup (\bar{A} \cap B)$.
\end{definition}

Mathematically :\\
let w be a word over an alphabet \alphabet{}, \automaton{} an automaton and \langU{} the language to be learnt, then
\[ member(w) =
  \begin{cases}
    \text{True}  & \quad \text{if } w \in U \\
    \text{False} & \quad \text{otherwise}
  \end{cases}
\]
\[ equiv(\automatonN{}) =
  \begin{cases}
    \text{True} & \quad \text{if } \automatonN{} \text{ recognizes } U           \\
    w           & \quad \text{otherwise, where } w \in U \Delta L(\automatonN{})
  \end{cases}
\]


\subsection{The observation table (O.T.)}
Every time an answer is received by the learner, it is important to store it somewhere to be able to increase the overall knowledge. In fact, every piece of information obtained from the teacher is immediatly added to the observation table (\textit{O.T.}).

\begin{definition}[Observation Table]
  The observation table is the memory of the learner, composed by two non-empty sets of words, $S$ and $E$, and a dictionnary $T$.
\end{definition}

We define also $SA = S \cdot \Sigma$ made by the concatenation of words of S and every symbol of \alphabet{} that are not in $S$, mathematically $\forall s \in S, \: \forall c \in \Sigma, \: SA = \{s \cdot c \text{ such that } s \cdot c \notin S \} $, and $S_{ext} = S \cup SA$ containing the union of $S$ and $SA$.
\begin{example}
  If $S = \{\varepsilon, a\}$ and $\Sigma = \{a, b\}$ then $S_{ext} = \{\varepsilon, a, b, aa, ab\}$.
\end{example}

The \textit{O.T.} can be seen as a matrix where rows are indexed by $S_{ext}$ and columns are indexed by $E$. The dictionnary $T$ finally stores for every cell $c_{i,j}$ if the concatenation of the $i^{th}$ word of $S_{ext}$ and the $j^{th}$ word of $E$ belongs to $U$. We split this matrix in the \upperPart{} with the rows of $S$ and the \lowerPart{} with rows of $SA$.


$S$ (resp. $E$) has an important property, that will be discussed next, since it is \textit{prefix-closed} (resp. \textit{suffix-closed}).

\begin{definition}
  A non-empty set of words $W$ is \textit{prefix-closed} (resp. \textit{suffix-closed}) if it contains every prefix (resp. \textit{suffix}) of every word of it. And, to garantee this property $W$ should of course contain $\varepsilon$.
\end{definition}

\subsection{Closedness and Consistence in L*}

In L* an \textit{O.T.} should be at every time closed and consistence.

\begin{definition}[Closedness]
  The \textit{O.T.} is closed if every row of the \lowerPart{} is also present in the \upperPart{}.
\end{definition}

If the table is not closed then there exists an element $s$ of $SA$ where $row(s)$ is not in the \upperPart{}. To restore the closedness of the observation table, $s$ will be promoted to $S$ and $\forall x \in \Sigma \text{ if } s \cdot x \notin SA \text{ then } s \cdot x \text{ is added to } SA$.

\begin{lemma}
  \label{lemmaPromoteLinePrefixClosedness}
  If we move an element from $SA$ to $S$ then $S$ will remain \textit{prefix-closed}.
\end{lemma}

\begin{proof}
  Every element of $SA$ is the concatenation of an element in $S$ and a letter of $\Sigma$. We have that $Pref(w) = Pref(w' \cdot a) = \{w' \cdot a\} \cup Pref(w')$ and every $Pref(w')$ is already in $S$ since $S$ is \textit{prefix-closed}. Therefore adding \word{} won't inpact the \textit{prefix-closedness} of $S$.
\end{proof}

\begin{definition}[Consistence]
  The \textit{O.T.} is consistent if for every $s_1,s_2 \in S$ and $row(s_1) = row(s_2)$, in this case $s_1,s_2$ are colled similar rows, then for every $x \in \Sigma$, $row(s_1 \cdot x) = row(s_2 \cdot x)$.
\end{definition}

If the table is not consistent, we have $row(w_1) = row(w_2)$ and $row(w_1 \cdot x) \neq row(w_2 \cdot x)$ for some $x \in \Sigma \text{ and some }w_1, w_2 \in S$. We can restore the consistence by making $w_1$ and $w_2$ no more similar: we find an $e \in E$ such that $T(w_1 \cdot x \cdot e) \neq T(w_2 \cdot x \cdot e)$ and we add $x \cdot e$ in $E$. In this way, the new bit of $row(w_1)$ is different from the new bit of $row(w_2)$ therefore the two rows are no more similar.

\begin{lemma}
  If we move an element of the type $x \cdot e$ where $x \in Sigma \text{ and } e \in E$ then $E$ remains \textit{suffix-closed}.
\end{lemma}

The proof is analogue to the proof of \cref{lemmaPromoteLinePrefixClosedness}.

\subsection{L* : Automaton creation}

When the observation table is closed and consistent, the Learner can send to Teacher a conjecture of the language the it has understood so far.

The conjecture is made on the form of an automaton where :
\begin{itemize}
  \item $Q = \{row(s), \forall s \in S\}$;
  \item $\delta(row(s), x) = row(s \cdot x), \forall s \in S, x \in \Sigma\}$;
  \item $q_I = row(\varepsilon)$;
  \item $F = \{row(s) | s \in S \text{ and } T(s) = 1 \}$.
\end{itemize}

After the sending of the conjecture, if the Teacher answers \textit{Yes} the algorithm stops, otherwise a counter-exemple $c$ is provided. $c$ is added to the $S$ set and if needed $S$ is completed to reamins prefix-closed and for $\forall x \in \Sigma, \text{ if } c \cdot x \notin S_{ext}  \text{ then } SA = SA \cup \{c \cdot x\}$.

\begin{lemma}
  \label{lemma:L_trans_from_QI}
  Let $q_I$ be the initial state and $s $ a word in $S_{ext}$ then $\delta(q_I, s) = row(s)$.
\end{lemma}

\begin{proof}
  We proove this by induction.\\
  Let's take a word $w$ over $S_{ext}$ and let $q_I$ be the initial state. \\
  If $length(w) = 0$, then $\delta(q_I, \varepsilon) = \delta(row(\varepsilon), \varepsilon) =  row(\varepsilon \cdot \varepsilon) = row(\varepsilon) = q_I$ that is true by definition.\\
  Let's suppose this property true for every word $w_n \in S_{ext}$ of length $n$, we want to proove that $\delta(q_I, w_{n+1}) = row(w_{n+1})$ for a word $w \in S_{ext}$ of length $n+1$.\\
  Let $w_{n+1}$ be a word of length $n+1$ and let $w = w_n \cdot x$ where $x \in \Sigma$ and $w_n$ is the prefix of $w_{n+1}$ with length $n$. Since $S_{ext}$ is prefix closed, then $w_n$ should exists.\\
  We have $\delta(q_I, w_{n+1}) = \delta(q_I, w_n \cdot x) = \delta(\delta(q_I, w_n), x)$. By the induction hypothesis, $\delta(q_I, w_n)$ exists since $length(w_n) = n$ and is equal to $row(w_n)$, therefore $\delta(\delta(q_I, w_n), x) = \delta(row(w_n), x)$. \\
  The \textit{O.T.} is closed so $\exists s \in S$ such that $row(w_n) = row(s)$ and so $\delta(row(w_n), x) = \delta(row(s), x)$.\\
  By definition of the transition function, $\delta(row(s), x) = row(s \cdot x)$ and by construction of the $O.T$, for every $s \in S$ there exists an element in $S_{ext}$ equals to the concatenation of this word and a letter of $\Sigma$.\\
  We can conclude that $\delta(q_I, w_{n+1}) = \delta(row(s), x) = row(s \cdot x)$, and, again, since the table is closed, $\exists s' \in S$ such that $row(s \cdot x) = row(s')$ and since every row of the upper-part is linked to a state $q_i$ of \automaton{} and this state correspond the ending state of the run of the word $w_{n+1}$.
\end{proof}

\begin{lemma}
  \label{lemma:L_acceptance}
  Let $s \in S_{ext} \text{ and } e \in E$, then $\delta(q_I, s \cdot e)$ is final if $T(s \cdot e) = 1$.
\end{lemma}

\begin{proof}
  As previous lemma, we proove this by induction on the length of the word $e$.\\
  If $length(e) = 0$, then $e = \varepsilon$ and by definition, $row(s \cdot \varepsilon) = row(s)$ is acceptant if $T(s) = 1$.\\
  Let's suppose this property true for every word $e_n$ of length $n$.\\
  Let $e_{n+1} \in E$ be a word of length $n + 1$, $e_n \in E$ the suffix of $e_{n+1}$ of length $n - 1$ and $x \in \Sigma$ such that $x \cdot e_n = e_{n+1}$. Since $E$ is suffix close, we know that $e_n$ should exist in $E$.\\
  We have that $\delta(q_I, s \cdot e_{n+1}) = \delta(q_I, s \cdot x \cdot e_n) = \delta(\delta(q_I, s), x \cdot e_n) = \delta(row(s), x \cdot e_n) = \delta(\delta(row(s), x), e_n)$.\\
  Since the table is closed, $\exists s' \in S$ such that $row(s) = row(s')$, and so $\delta(row(s), x) = \delta(row(s'), x) = row(s' \cdot x)$ since, as for the preceding lemma. Again, since the table is closed, $\exists s'' \in S$ such that $row(s' \cdot x) = row(s'')$.\\
  We have so that $\delta(q_I, s \cdot e_{n+1}) = \delta(row(s''), e_n) = \delta(\delta(q_I, s''), e_n) = \delta(q_I, s'' \cdot e_n)$.\\
  Since $s'' \in S_{ext}$ and $e_n$ has length $n$, we can proove that  $\delta(q_I, s \cdot e_{n+1})$ is in acceptant if $T(s \cdot e_{n+1}) = T(s'' \cdot e_n) = 1$.
\end{proof}

\begin{lemma}
  The automaton created is deterministic.
\end{lemma}

\begin{proof}
  We know that for every row $s_1 \in S$ and for every $x \in \Sigma$, $s_1 \cdot x \in S_{ext}$. Moreover, since the table is consistent, for every $s_2 \in S$ where $row(s_1)$ and $row(s_2)$ are similar, we have that $row(s_1 \cdot x) = row(s_2 \cdot x)$. Therefore there exists only one successor for every state $q \in Q$ and every letter $x \in \Sigma$.
\end{proof}

\begin{lemma}
  The automaton created is minimum.
\end{lemma}

\begin{proof}
  We can proove this lemma by contradiction. Let suppose that $A$ is not minimun and, therefore, that it is possible to merge \footnote{Two states can be merged if they recognize the same language or as in this case, they have same incoming and outgoing arrows} some states $q_i, q_j$ to minimize it.
  By construction, $q_i$ and $q_j$ are linked to two different rows $r_1, r_2$ of the observation table.
  Let $e \in E$ be a column which is accepted by only one between $r_1, r_2$.
  Then it means that $e$ is accepted by only one of the residual languages recognized by $q_i$ and $q_j$ and therefore we cannot merge them.
  We have prooved that it is not possible to merge any couple of state $q_i, q_j \in Q$ and so the automaton is minimum.
\end{proof}

\subsection{L* analysis}
\subsubsection{Correcteness}
The goal of the algorithm is to find an automaton recognizing the language of the teacher. The solution found by the Learner is correct since it has been accepted by the Teacher.
\subsubsection{Terminaison}
The algorithm terminates only if the Teacher answer $Yes$ to a \textit{equivalence query} of the Learner.

We know, by definition, that the language $U$ known by the teacher is regular. It means that the number $n$ of its residuals is finite implying that the number of states of the minimum DFA recognizing it and the number of different rows in the $O.T$ is finite (and equal to $n$).

If in a certain moment we have $n' < n$ different rows and the table is closed and consistent, the Learner make its conjecture and sends it to the Teacher. This conjecture cannot be the good one, and the counter-example provided will have an associated row similar to a row in $S$ but which makes the \textit{O.T.} no more consistent. The Learner repeats the algorithm, and every time the table is not consistent, the $n'$ will increase of one. When $n' = n$ the conjecture will have $n$ states, the same of the minimum DFA, and therefore since a minimum DFA is unique, the teacher will answer $Yes$ to the last conjecture allowing the algorithm to stop.

\subsubsection{Time complexity}
Let suppose that the \cref{L_star_algo} takes constant time to check if the table is consistent and closed and to create an automaton from the $O.T$ and pose $A$ the minimum DFA recognizing $U$.

The time complexity should be measured on the number of cells of the $O.T$.

In the wrost case, the number of columns $n$ (that is the cardinal of $E$) equals the number of states $A$, since at most we should have to make the table consistent $n-1$ times.

The size of $S$ is another key factor for the time complexity. Its size really depends on the length $m$ of the counter-exemple provided by the Teacher. At least $S$ has $n$ rows, one per number of column, but considering the length of $m$, and knowing that all prefix of $m$ will be added to $S$, then $|S|$ will have $O(n \times m)$ rows.

The size of $SA$ is at most $O(|\Sigma|)$ times the length $|S|$ since for every word in $|S|$ we can potentially have $|\Sigma|$ successors to add in $SA$.

In conclusion we have $O(n)$ columns and $O(|\Sigma| \times n \times m)$ rows, asking an overall complexity of $O(n \times |\Sigma| \times n \times m) = O(|\Sigma| \times n^2 \times m) = O(n^2 \times m)$ since $|\Sigma|$ is constant. The time complexity is so polynomial on the size of the automaton and the larger counter-exemple given by the teacher.